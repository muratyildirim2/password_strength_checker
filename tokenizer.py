# tokenizer.py

def word(password):
    character = []
    for i in password:
        character.append(i)
    return character
